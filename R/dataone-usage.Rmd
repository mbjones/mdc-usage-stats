---
title: "DataONE Usage Statistics"
author: "Matt Jones"
date: "April 9, 2015"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(ggplot2)
library(scales)
source("geohash.R")
```

Create a graph of data downloads for a given Member Node, such as the KNB:

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#' Query DataONE and summarize download counts by month
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @return data frame with the counts for each month for that query
counts_by_month <- function(query='nodeId:urn\\:node\\:KNB') {
    d1_uri_base <- 'https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    d1_uri_params <- '&fq=event:read&facet=true&facet.range=dateLogged&facet.range.start=2005-01-01T01:01:01Z&facet.range.end=2015-03-31T24:59:59Z&facet.range.gap=%2B1MONTH&wt=json'
    cert="/Users/jones/certs/cn-ucsb-1.dataone.org.pem"
    sslkey="/Users/jones/certs/cn-ucsb-1.dataone.org.key"
    d1_uri <- paste0(d1_uri_base, query, d1_uri_params)
    response <- GET(d1_uri, config=config(sslcert = cert, sslkey = sslkey))
    if (response$status_code != 200) {
        print("Failed downloading usage stats...")
    }
    results <- content(response)
    document <- fromJSON(results)
    unparsed <- document$facet_counts$facet_ranges$dateLogged$counts
    dates <- as.Date(unparsed[seq(1, length(unparsed), 2)])
    downloads <- as.numeric(unparsed[seq(2, length(unparsed), 2)])
    countdata <- data.frame(dates, downloads, stringsAsFactors=FALSE)
    return(countdata)
}

#' Plot a bar graph of a set of download statistics
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param label the title for the graph
plot_downloads <- function(query='nodeId:urn\\:node\\:KNB', label='KNB Downloads') {
    countdata <- counts_by_month(query)
    #print(countdata)
    g <- ggplot(countdata, aes(x=dates, y=downloads)) + 
        geom_bar(stat="identity") +
        xlab("Date") +
        scale_y_continuous(name="Downloads", labels = comma) +
        theme_bw() +
        theme(legend.title = element_blank()) +
        ggtitle(label)
    print(g)
}
     
```

Downloads for all of DataONE:
```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_downloads('*:*+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'All DataONE Downloads')
```

And for selected nodes:
```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_downloads('nodeId:urn\\:node\\:KNB+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'KNB Downloads')
plot_downloads('nodeId:urn\\:node\\:DRYAD+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'Dryad Downloads')
plot_downloads('nodeId:urn\\:node\\:PISCO+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'PISCO Downloads')
plot_downloads('nodeId:urn\\:node\\:ORNLDAAC+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'ORNL Downloads')
plot_downloads('nodeId:urn\\:node\\:USGSCSAS+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'USGS Downloads')
plot_downloads('nodeId:urn\\:node\\:LTER+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'LTER Downloads')
plot_downloads('nodeId:urn\\:node\\:CDL+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'CDL Downloads')
plot_downloads('nodeId:urn\\:node\\:TFRI+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'TFRI Downloads')
plot_downloads('nodeId:urn\\:node\\:USANPN+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'USANPN Downloads')
plot_downloads('nodeId:urn\\:node\\:SEAD+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'SEAD Downloads')
plot_downloads('nodeId:urn\\:node\\:GOA+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'GOA Downloads')
plot_downloads('nodeId:urn\\:node\\:KUBI+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'KUBI Downloads')
plot_downloads('nodeId:urn\\:node\\:LTER_EUROPE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'LTER EUROPE Downloads')
plot_downloads('nodeId:urn\\:node\\:EDACGSTORE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'EDAC Downloads')
plot_downloads('nodeId:urn\\:node\\:IOE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'IOE Downloads')
plot_downloads('nodeId:urn\\:node\\:GLEON+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'GLEON Downloads')
```

# Map Downloads by Geohash
```{r, echo=FALSE, message=FALSE, warning=FALSE}

#' Query DataONE and summarize download counts by geohash
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param level an interger from 1 to 9 indicating the geohash level to use for grouping
#' @return data frame with the counts for each geohash for that query
counts_by_geohash <- function(query='nodeId:urn\\:node\\:KNB', level=3) {
    #               https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    # &fq=event:read&facet=true&facet.field=geohash_4&wt=json
    d1_uri_base <- 'https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    d1_uri_params <- '&facet.limit=5000&wt=json&fq=event:read&facet=true&facet.field='
    fieldname <- paste0('geohash_', level)
    cert="/Users/jones/certs/cn-ucsb-1.dataone.org.pem"
    sslkey="/Users/jones/certs/cn-ucsb-1.dataone.org.key"
    d1_uri <- paste0(d1_uri_base, query, d1_uri_params, fieldname)
    response <- GET(d1_uri, config=config(sslcert = cert, sslkey = sslkey))
    if (response$status_code != 200) {
        print("Failed downloading usage stats...")
    }
    results <- content(response)
    document <- fromJSON(results)
    unparsed <- document$facet_counts$facet_fields[[fieldname]]
    geohash <- unparsed[seq(1, length(unparsed), 2)]
    downloads <- as.numeric(unparsed[seq(2, length(unparsed), 2)])
    countdata <- data.frame(geohash, downloads, stringsAsFactors=FALSE)
    return(countdata)
}

counts <- counts_by_geohash('nodeId:urn\\:node\\:KNB', 3)

bounds <- as.data.frame(do.call(rbind, lapply(counts$geohash, function(x) {
    cbind(x, as.data.frame(matrix(unlist(geohash_bounds(x)), nrow=1)), stringsAsFactors=F)
    }
    )))
colnames(bounds) <- c('geohash', 'sw.lat', 'sw.lon', 'ne.lat', 'ne.lon')
data <- merge(counts, bounds)
data.subset <- subset(data, downloads<100000000 & downloads > 100)

#world<-get_map("Spain",zoom=2)  # ggmap won't get the whole world, zoom level must be >= 3
world <- map_data("world")
data$alpha <- data$downloads/1000
worldmap <- ggplot(world, aes(x=long, y=lat, group=group)) +
  geom_path(color='grey20')
  #coord_map()
worldmap +
    geom_rect(data=data, aes(xmin=sw.lon, xmax=ne.lon, ymin=sw.lat, ymax=ne.lat), fill="red", alpha=0.6, inherit.aes = FALSE)
    #annotate("point",x=7.257885,y=46.79049,size=7) +
    #annotate("text", x=7.257885,y=46.79049,label="Golden Swiss Area",colour="white",size=3)
```

See also related graphs on DataONE: https://monitor.dataone.org/_production_history/log_history.html
