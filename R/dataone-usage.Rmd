---
title: "DataONE Usage Statistics"
author: "Matt Jones"
date: "April 9, 2015"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(ggplot2)
library(scales)
library(plyr)
library(reshape2)
source("R/geohash.R")
```

Create a graph of data downloads for a given Member Node, such as the KNB:

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#' Query DataONE and summarize download counts by month
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @return data frame with the counts for each month for that query
counts_by_month <- function(query='nodeId:urn\\:node\\:KNB', filter=as.character(NA)) {
    # https://cn.dataone.org/cn/v1/query/logsolr/select?q=event:read+AND+isRepeatVisit:false+AND+inPartialRobotList:false&facet=true&facet.field=pid&facet.mincount=1&facet.limit=1000000&facet.offset=0
    d1_uri_base <- 'https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    filter_counter <- '+AND+isRepeatVisit:false+AND+inFullRobotList:false'
    filter_partial <- '+AND+isRepeatVisit:false+AND+inPartialRobotList:false'
    d1_uri_params <- '&fq=event:read&facet=true&facet.range=dateLogged&facet.range.start=2005-01-01T01:01:01Z&facet.range.end=2015-08-31T24:59:59Z&facet.range.gap=%2B1MONTH&wt=json'
    cert="/Users/jones/certs/cn-ucsb-1.dataone.org.pem"
    sslkey="/Users/jones/certs/cn-ucsb-1.dataone.org.key"
    if (!is.na(filter) && grepl('counter', filter) ) {
        fullquery <- paste0(query, filter_counter)
    } else if (!is.na(filter) && grepl('partial', filter) ) {
        fullquery <- paste0(query, filter_partial)
    } else {
        fullquery <- query
    }
    d1_uri <- paste0(d1_uri_base, fullquery, d1_uri_params)
    print(d1_uri)
    #response <- GET(d1_uri, config=config(sslcert = cert, sslkey = sslkey))
    response <- GET(d1_uri)
    if (response$status_code != 200) {
        print("Failed downloading usage stats...")
    }
    results <- content(response)
    document <- fromJSON(results)
    unparsed <- document$facet_counts$facet_ranges$dateLogged$counts
    dates <- as.Date(unparsed[seq(1, length(unparsed), 2)])
    downloads <- as.numeric(unparsed[seq(2, length(unparsed), 2)])
    countdata <- data.frame(dates, downloads, stringsAsFactors=FALSE)
    if (is.na(filter)) {
        filter <- 'none'
    }
    countdata$filter <- filter
    return(countdata)
}

#' Plot a bar graph of a set of download statistics
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param label the title for the graph
plot_downloads <- function(query='nodeId:urn\\:node\\:KNB', label='KNB Downloads') {
    countdata <- counts_by_month(query)
    #print(countdata)
    g <- ggplot(countdata, aes(x=dates, y=downloads)) + 
        geom_bar(stat="identity") +
        xlab("Date") +
        scale_y_continuous(name="Downloads", labels = comma, limits=c(0,400000)) +
        theme_bw() +
        theme(legend.title = element_blank()) +
        ggtitle(label)
    print(g)
}

#' Plot a bar graph of a set of download statistics, comparing COUNTER, partial, and no filtering
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param label the title for the graph
plot_comparison <- function(query='nodeId:urn\\:node\\:KNB', label='KNB Downloads') {
    countdata_none <- counts_by_month(query)
    countdata_counter <- counts_by_month(query, filter='counter')
    countdata_partial <- counts_by_month(query, filter='partial')
    countdata <- rbind.fill(list(countdata_none, countdata_counter, countdata_partial))
    
    #print(countdata)
    g <- ggplot(countdata, aes(x=dates, y=downloads)) + 
        geom_bar(stat="identity") +
        facet_grid(. ~ filter) +
        xlab("Date") +
        scale_y_continuous(name="Downloads", labels = comma, limits=c(0,400000)) +
        #scale_y_continuous(name="Downloads", labels = comma) +
        theme_bw() +
        theme(legend.title = element_blank()) +
        ggtitle(label)
    print(g)
}

#' Calculate the percent change in usage based on counter and partial filters
#' @param countdata a data frame containing usage counts for none, partial, and counter usage
calc_change <- function(countdata) {
    cmelt <- melt(countdata, id.vars=c("dates","filter"))
    ccast <- dcast(cmelt, dates ~ filter)
    ccast$none[ccast$none == 0] <- 0.1
    ccast$counter_pct <- ccast$counter / ccast$none
    ccast$partial_pct <- ccast$partial / ccast$none
    ccast$diff <- ccast$counter - ccast$partial
    return(ccast)
}
```

Downloads for all of DataONE:
```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_comparison(query='*:*+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', label='All DataONE Downloads')
```

And for selected nodes:
```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_comparison('nodeId:urn\\:node\\:KNB+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'KNB Downloads')
plot_comparison('nodeId:urn\\:node\\:DRYAD+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'Dryad Downloads')
plot_comparison('nodeId:urn\\:node\\:PISCO+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'PISCO Downloads')
plot_comparison('nodeId:urn\\:node\\:ORNLDAAC+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'ORNL Downloads')
plot_comparison('nodeId:urn\\:node\\:USGSCSAS+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'USGS Downloads')
plot_comparison('nodeId:urn\\:node\\:LTER+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'LTER Downloads')
plot_downloads('nodeId:urn\\:node\\:CDL+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'CDL Downloads')
plot_downloads('nodeId:urn\\:node\\:TFRI+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'TFRI Downloads')
plot_downloads('nodeId:urn\\:node\\:USANPN+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'USANPN Downloads')
plot_downloads('nodeId:urn\\:node\\:SEAD+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'SEAD Downloads')
plot_downloads('nodeId:urn\\:node\\:GOA+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'GOA Downloads')
plot_downloads('nodeId:urn\\:node\\:KUBI+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'KUBI Downloads')
plot_downloads('nodeId:urn\\:node\\:LTER_EUROPE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'LTER EUROPE Downloads')
plot_downloads('nodeId:urn\\:node\\:EDACGSTORE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'EDAC Downloads')
plot_downloads('nodeId:urn\\:node\\:IOE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'IOE Downloads')
plot_downloads('nodeId:urn\\:node\\:GLEON+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'GLEON Downloads')
```

# Map Downloads by Geohash
```{r, echo=FALSE, message=FALSE, warning=FALSE}

#' Query DataONE and summarize download counts by geohash
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param level an interger from 1 to 9 indicating the geohash level to use for grouping
#' @return data frame with the counts for each geohash for that query
counts_by_geohash <- function(query='nodeId:urn\\:node\\:KNB', level=3) {
    #               https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    # &fq=event:read&facet=true&facet.field=geohash_4&wt=json
    d1_uri_base <- 'https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    d1_uri_params <- '&facet.limit=5000&wt=json&fq=event:read&facet=true&facet.field='
    fieldname <- paste0('geohash_', level)
    cert="/Users/jones/certs/cn-ucsb-1.dataone.org.pem"
    sslkey="/Users/jones/certs/cn-ucsb-1.dataone.org.key"
    d1_uri <- paste0(d1_uri_base, query, d1_uri_params, fieldname)
    response <- GET(d1_uri, config=config(sslcert = cert, sslkey = sslkey))
    if (response$status_code != 200) {
        print("Failed downloading usage stats...")
    }
    results <- content(response)
    document <- fromJSON(results)
    unparsed <- document$facet_counts$facet_fields[[fieldname]]
    geohash <- unparsed[seq(1, length(unparsed), 2)]
    downloads <- as.numeric(unparsed[seq(2, length(unparsed), 2)])
    countdata <- data.frame(geohash, downloads, stringsAsFactors=FALSE)
    return(countdata)
}

counts <- counts_by_geohash('nodeId:urn\\:node\\:KNB', 3)

bounds <- as.data.frame(do.call(rbind, lapply(counts$geohash, function(x) {
    cbind(x, as.data.frame(matrix(unlist(geohash_bounds(x)), nrow=1)), stringsAsFactors=F)
    }
    )))
colnames(bounds) <- c('geohash', 'sw.lat', 'sw.lon', 'ne.lat', 'ne.lon')
data <- merge(counts, bounds)
data.subset <- subset(data, downloads<100000000 & downloads > 100)

library(maps)
library(mapdata)
#world<-get_map("Spain",zoom=2)  # ggmap won't get the whole world, zoom level must be >= 3
#world <- map_data("world")
world <- map_data('world2')
#world <- map_data('world2Hires')
data$alpha <- data$downloads/1000
worldmap <- ggplot(world, aes(x=long, y=lat, group=group)) +
  geom_path(color='grey20')
  #coord_map()
worldmap +
    geom_rect(data=data, aes(xmin=sw.lon, xmax=ne.lon, ymin=sw.lat, ymax=ne.lat), fill="red", alpha=0.6, inherit.aes = FALSE)
    #annotate("point",x=7.257885,y=46.79049,size=7) +
    #annotate("text", x=7.257885,y=46.79049,label="Golden Swiss Area",colour="white",size=3)
```

See also related graphs on DataONE: https://monitor.dataone.org/_production_history/log_history.html
