---
title: "DataONE Usage Statistics"
author: "Matt Jones"
date: "April 9, 2015"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(ggplot2)
library(scales)
library(plyr)
library(reshape2)
library(dataone)
library(grid)
library(gridExtra)
library(cowplot)
source("R/geohash.R")
```

Create a graph of data downloads for a given Member Node, such as the KNB:

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#' Query DataONE and summarize download counts by month
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @return data frame with the counts for each month for that query
counts_by_month <- function(query='nodeId:urn\\:node\\:KNB', filter=as.character(NA)) {
    # https://cn.dataone.org/cn/v1/query/logsolr/select?q=event:read+AND+isRepeatVisit:false+AND+inPartialRobotList:false&facet=true&facet.field=pid&facet.mincount=1&facet.limit=1000000&facet.offset=0
    d1_uri_base <- 'https://cn.dataone.org/cn/v1/query/logsolr/?q='
    filter_counter <- '+AND+isRepeatVisit:false+AND+inFullRobotList:false'
    filter_partial <- '+AND+isRepeatVisit:false+AND+inPartialRobotList:false'
    d1_uri_params <- '&fq=event:read&facet=true&facet.range=dateLogged&facet.range.start=2005-01-01T01:01:01Z&facet.range.end=2016-03-31T24:59:59Z&facet.range.gap=%2B1MONTH&wt=json'
    cert="/Users/jones/certs/cn-ucsb-1.dataone.org.pem"
    sslkey="/Users/jones/certs/cn-ucsb-1.dataone.org.key"
    if (!is.na(filter) && grepl('counter', filter) ) {
        fullquery <- paste0(query, filter_counter)
    } else if (!is.na(filter) && grepl('partial', filter) ) {
        fullquery <- paste0(query, filter_partial)
    } else {
        fullquery <- query
    }
    d1_uri <- paste0(d1_uri_base, fullquery, d1_uri_params)
    print(d1_uri)
    #response <- GET(d1_uri, config=config(sslcert = cert, sslkey = sslkey))
    response <- GET(d1_uri)
    if (response$status_code != 200) {
        print("Failed downloading usage stats...")
    }
    results <- content(response, as="text")
    document <- fromJSON(results)
    unparsed <- document$facet_counts$facet_ranges$dateLogged$counts
    dates <- as.Date(unparsed[seq(1, length(unparsed), 2)])
    downloads <- as.numeric(unparsed[seq(2, length(unparsed), 2)])
    countdata <- data.frame(dates, downloads, stringsAsFactors=FALSE)
    if (is.na(filter)) {
        filter <- 'none'
    }
    countdata$filter <- filter
    countdata$filter <- factor(countdata$filter, levels=c("none", "partial", "counter"), ordered=TRUE)
    #levels(countdata$filter) <- c("none", "partial", "counter")
    
    return(countdata)
}

#' Plot a bar graph of a set of download statistics
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param label the title for the graph
plot_downloads <- function(query='nodeId:urn\\:node\\:KNB', label='KNB Downloads') {
    countdata <- counts_by_month(query, filter='partial')
    g <- ggplot(countdata, aes(x=dates, y=downloads)) + 
        geom_bar(stat="identity") +
#        geom_bar(stat="identity", drop=TRUE) +
        xlab("Date") +
        #scale_y_continuous(name="Downloads", labels = comma, limits=c(0,100000)) +
        scale_y_log10(name="Downloads", labels = comma, limits=c(1,500000)) +
        theme_bw() +
        theme(legend.title = element_blank()) +
        ggtitle(label)
    return(g)
}

#' Plot a bar graph of a set of download statistics, comparing COUNTER, partial, and no filtering
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param label the title for the graph
plot_comparison <- function(query='nodeId:urn\\:node\\:KNB', label='KNB Downloads') {
    countdata_none <- counts_by_month(query)
    countdata_counter <- counts_by_month(query, filter='counter')
    countdata_partial <- counts_by_month(query, filter='partial')
    countdata <- rbind.fill(list(countdata_none, countdata_counter, countdata_partial))
    
    g <- ggplot(countdata, aes(x=dates, y=downloads)) + 
        geom_bar(stat="identity") +
        facet_grid(. ~ filter) +
        xlab("Date") +
        #scale_y_continuous(name="Downloads", labels = comma, limits=c(0,400000)) +
        scale_y_log10(name="Downloads", labels = comma, limits=c(1,500000)) +
        #scale_y_continuous(name="Downloads", labels = comma) +
        theme_bw() +
        theme(legend.title = element_blank(), 
              axis.text.x = element_text(angle=70, vjust=0.5)) +
        ggtitle(label)
    return(g)
}

#' Calculate the percent change in usage based on counter and partial filters
#' @param countdata a data frame containing usage counts for none, partial, and counter usage
calc_change <- function(countdata) {
    cmelt <- melt(countdata, id.vars=c("dates","filter"))
    ccast <- dcast(cmelt, dates ~ filter)
    ccast$none[ccast$none == 0] <- 0.1
    ccast$counter_pct <- ccast$counter / ccast$none
    ccast$partial_pct <- ccast$partial / ccast$none
    ccast$diff <- ccast$counter - ccast$partial
    return(ccast)
}
```

Downloads for all of DataONE:
```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_comparison(query='*:*+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', label='All DataONE Downloads')
```

And for all member node repositories:
```{r, echo=FALSE, message=FALSE, warning=FALSE}
cn <- CNode()
nodes_list <- listNodes(cn)
nodes_df <- do.call("rbind", lapply(nodes_list, function (x) { as.data.frame(cbind(x@identifier, x@type, x@name)) } ) )
colnames(nodes_df) <- c("identifier", "type", "name")
mns <- nodes_df[nodes_df$type == 'mn',]

plot_mn <- function(df) { 
    escaped_id <- gsub(':', '\\\\:', df$identifier)
    exclude_ip_fragment <- '+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)'
    query <- paste0('nodeId:', escaped_id, exclude_ip_fragment)
    return(plot_downloads(query, substr(df$name, 1, 25)))
}

mn_plots <- by(mns, 1:nrow(mns), plot_mn)
p1 <- plot_grid(plotlist=mn_plots[1:12], ncol=3, nrow=4)
ggsave(paste0("mn-p01-partial-", date_label, ".pdf"), p1, width = 11, height = 8.5)
p2 <- plot_grid(plotlist=mn_plots[13:24], ncol=3, nrow=4)
ggsave(paste0("mn-p02-partial-", date_label, ".pdf"), p2, width = 11, height = 8.5)
p3 <- plot_grid(plotlist=mn_plots[25:nrow(mn_plots)], ncol=3, nrow=4)
ggsave(paste0("mn-p03-partial-", date_label, ".pdf"), p3, width = 11, height = 8.5)

plot_mn_comparison <- function(df) { 
    escaped_id <- gsub(':', '\\\\:', df$identifier)
    exclude_ip_fragment <- '+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)'
    query <- paste0('nodeId:', escaped_id, exclude_ip_fragment)
    return(plot_comparison(query, substr(df$name, 1, 25)))
}

date_label <- "2016-03-31"
mn_comps <- by(mns, 1:nrow(mns), plot_mn_comparison)
p1 <- plot_grid(plotlist=mn_comps[1:12], ncol=3, nrow=4)
ggsave(paste0("mn-p01-comparison-", date_label, ".pdf"), p1, width = 11, height = 8.5)
p2 <- plot_grid(plotlist=mn_comps[13:24], ncol=3, nrow=4)
ggsave(paste0("mn-p02-comparison-", date_label, ".pdf"), p2, width = 11, height = 8.5)
p3 <- plot_grid(plotlist=mn_comps[25:nrow(mn_comps)], ncol=3, nrow=4)
ggsave(paste0("mn-p03-comparison-", date_label, ".pdf"), p3, width = 11, height = 8.5)

#plot_comparison('nodeId:urn\\:node\\:KNB+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'KNB Downloads')
#plot_downloads('nodeId:urn\\:node\\:LTER_EUROPE+AND+-ipAddress:(128.111.54.80+OR+160.36.13.150+OR+64.106.40.6)', 'LTER EUROPE Downloads')
```

# Map Downloads by Geohash
```{r, echo=FALSE, message=FALSE, warning=FALSE}

#' Query DataONE and summarize download counts by geohash
#' @param query a SOLR-encoded query string to choose the set of records to include in the downloads
#' @param level an interger from 1 to 9 indicating the geohash level to use for grouping
#' @return data frame with the counts for each geohash for that query
counts_by_geohash <- function(query='nodeId:urn\\:node\\:KNB', level=3) {
    #               https://cn.dataone.org/cn/v1/query/logsolr/select?q='
    # &fq=event:read&facet=true&facet.field=geohash_4&wt=json
    d1_uri_base <- 'https://cn.dataone.org/cn/v1/query/logsolr/?q='
    d1_uri_params <- '&facet.limit=5000&wt=json&fq=event:read&facet=true&facet.field='
    fieldname <- paste0('geohash_', level)
    cert="/Users/jones/certs/cn-ucsb-1.dataone.org.pem"
    sslkey="/Users/jones/certs/cn-ucsb-1.dataone.org.key"
    d1_uri <- paste0(d1_uri_base, query, d1_uri_params, fieldname)
    response <- GET(d1_uri, config=config(sslcert = cert, sslkey = sslkey))
    if (response$status_code != 200) {
        print("Failed downloading usage stats...")
    }
    results <- content(response, as="text")
    document <- fromJSON(results)
    unparsed <- document$facet_counts$facet_fields[[fieldname]]
    geohash <- unparsed[seq(1, length(unparsed), 2)]
    downloads <- as.numeric(unparsed[seq(2, length(unparsed), 2)])
    countdata <- data.frame(geohash, downloads, stringsAsFactors=FALSE)
    return(countdata)
}

counts <- counts_by_geohash('nodeId:urn\\:node\\:KNB', 3)

bounds <- as.data.frame(do.call(rbind, lapply(counts$geohash, function(x) {
    cbind(x, as.data.frame(matrix(unlist(geohash_bounds(x)), nrow=1)), stringsAsFactors=F)
    }
    )))
colnames(bounds) <- c('geohash', 'sw.lat', 'sw.lon', 'ne.lat', 'ne.lon')
data <- merge(counts, bounds)
data.subset <- subset(data, downloads<100000000 & downloads > 100)

library(maps)
library(mapdata)
#world<-get_map("Spain",zoom=2)  # ggmap won't get the whole world, zoom level must be >= 3
#world <- map_data("world")
world <- map_data('world2')
#world <- map_data('world2Hires')
data$alpha <- data$downloads/1000
worldmap <- ggplot(world, aes(x=long, y=lat, group=group)) +
  geom_path(color='grey20')
  #coord_map()
worldmap +
    geom_rect(data=data, aes(xmin=sw.lon, xmax=ne.lon, ymin=sw.lat, ymax=ne.lat), fill="red", alpha=0.6, inherit.aes = FALSE)
    #annotate("point",x=7.257885,y=46.79049,size=7) +
    #annotate("text", x=7.257885,y=46.79049,label="Golden Swiss Area",colour="white",size=3)
```

See also related graphs on DataONE: https://monitor.dataone.org/_production_history/log_history.html
